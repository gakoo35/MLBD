{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP3 - Leukemia Feature Selection \n",
    "# Corpataux Sam, Koch Gaël"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_3_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_5_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_MA_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_MB_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_3_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_5_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_M_at</th>\n",
       "      <th>AFFX-M27830_3_at</th>\n",
       "      <th>AFFX-M27830_5_at</th>\n",
       "      <th>AFFX-M27830_M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.361346</td>\n",
       "      <td>0.450274</td>\n",
       "      <td>0.431178</td>\n",
       "      <td>0.405517</td>\n",
       "      <td>0.160812</td>\n",
       "      <td>0.568845</td>\n",
       "      <td>0.236371</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.793796</td>\n",
       "      <td>0.101112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718074</td>\n",
       "      <td>0.433772</td>\n",
       "      <td>0.516903</td>\n",
       "      <td>0.480186</td>\n",
       "      <td>0.416394</td>\n",
       "      <td>0.480112</td>\n",
       "      <td>0.474266</td>\n",
       "      <td>0.196546</td>\n",
       "      <td>0.455276</td>\n",
       "      <td>0.607962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.396426</td>\n",
       "      <td>0.559457</td>\n",
       "      <td>0.402577</td>\n",
       "      <td>0.437968</td>\n",
       "      <td>0.08913</td>\n",
       "      <td>0.526262</td>\n",
       "      <td>0.370959</td>\n",
       "      <td>0.118863</td>\n",
       "      <td>0.411771</td>\n",
       "      <td>0.231975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578789</td>\n",
       "      <td>0.305685</td>\n",
       "      <td>0.389508</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.567414</td>\n",
       "      <td>0.588449</td>\n",
       "      <td>0.575516</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.570179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.419317</td>\n",
       "      <td>0.436466</td>\n",
       "      <td>0.306609</td>\n",
       "      <td>0.479352</td>\n",
       "      <td>0.117863</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.348458</td>\n",
       "      <td>0.095052</td>\n",
       "      <td>0.621742</td>\n",
       "      <td>0.249171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47976</td>\n",
       "      <td>0.221501</td>\n",
       "      <td>0.248076</td>\n",
       "      <td>0.277969</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>0.498713</td>\n",
       "      <td>0.522232</td>\n",
       "      <td>0.157139</td>\n",
       "      <td>0.542367</td>\n",
       "      <td>0.655399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.424651</td>\n",
       "      <td>0.512677</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.484471</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>0.452757</td>\n",
       "      <td>0.393106</td>\n",
       "      <td>0.337601</td>\n",
       "      <td>0.481378</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534108</td>\n",
       "      <td>0.182823</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.196156</td>\n",
       "      <td>0.270626</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.414519</td>\n",
       "      <td>0.186461</td>\n",
       "      <td>0.468462</td>\n",
       "      <td>0.650308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.194097</td>\n",
       "      <td>0.355157</td>\n",
       "      <td>0.453368</td>\n",
       "      <td>0.180248</td>\n",
       "      <td>0.571522</td>\n",
       "      <td>0.188911</td>\n",
       "      <td>0.217023</td>\n",
       "      <td>0.772696</td>\n",
       "      <td>0.27619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65905</td>\n",
       "      <td>0.047018</td>\n",
       "      <td>0.224651</td>\n",
       "      <td>0.354375</td>\n",
       "      <td>0.32994</td>\n",
       "      <td>0.404139</td>\n",
       "      <td>0.184868</td>\n",
       "      <td>0.136972</td>\n",
       "      <td>0.24414</td>\n",
       "      <td>0.637725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF    1007_s_at   1053_at    117_at    121_at 1255_g_at   1294_at  \\\n",
       "GSM329407  0.361346  0.450274  0.431178  0.405517  0.160812  0.568845   \n",
       "GSM329408  0.396426  0.559457  0.402577  0.437968   0.08913  0.526262   \n",
       "GSM329409  0.419317  0.436466  0.306609  0.479352  0.117863  0.532214   \n",
       "GSM329410  0.424651  0.512677  0.217119  0.484471  0.222672  0.452757   \n",
       "GSM329411  0.287776  0.194097  0.355157  0.453368  0.180248  0.571522   \n",
       "\n",
       "ID_REF      1316_at   1320_at 1405_i_at   1431_at  ...  \\\n",
       "GSM329407  0.236371  0.020181  0.793796  0.101112  ...   \n",
       "GSM329408  0.370959  0.118863  0.411771  0.231975  ...   \n",
       "GSM329409  0.348458  0.095052  0.621742  0.249171  ...   \n",
       "GSM329410  0.393106  0.337601  0.481378  0.078431  ...   \n",
       "GSM329411  0.188911  0.217023  0.772696   0.27619  ...   \n",
       "\n",
       "ID_REF    AFFX-HUMISGF3A/M97935_3_at AFFX-HUMISGF3A/M97935_5_at  \\\n",
       "GSM329407                   0.718074                   0.433772   \n",
       "GSM329408                   0.578789                   0.305685   \n",
       "GSM329409                    0.47976                   0.221501   \n",
       "GSM329410                   0.534108                   0.182823   \n",
       "GSM329411                    0.65905                   0.047018   \n",
       "\n",
       "ID_REF    AFFX-HUMISGF3A/M97935_MA_at AFFX-HUMISGF3A/M97935_MB_at  \\\n",
       "GSM329407                    0.516903                    0.480186   \n",
       "GSM329408                    0.389508                    0.370612   \n",
       "GSM329409                    0.248076                    0.277969   \n",
       "GSM329410                    0.355785                    0.196156   \n",
       "GSM329411                    0.224651                    0.354375   \n",
       "\n",
       "ID_REF    AFFX-HUMRGE/M10098_3_at AFFX-HUMRGE/M10098_5_at  \\\n",
       "GSM329407                0.416394                0.480112   \n",
       "GSM329408                0.567414                0.588449   \n",
       "GSM329409                0.480558                0.498713   \n",
       "GSM329410                0.270626                0.520508   \n",
       "GSM329411                 0.32994                0.404139   \n",
       "\n",
       "ID_REF    AFFX-HUMRGE/M10098_M_at AFFX-M27830_3_at AFFX-M27830_5_at  \\\n",
       "GSM329407                0.474266         0.196546         0.455276   \n",
       "GSM329408                0.575516         0.296013         0.499546   \n",
       "GSM329409                0.522232         0.157139         0.542367   \n",
       "GSM329410                0.414519         0.186461         0.468462   \n",
       "GSM329411                0.184868         0.136972          0.24414   \n",
       "\n",
       "ID_REF    AFFX-M27830_M_at  \n",
       "GSM329407         0.607962  \n",
       "GSM329408         0.570179  \n",
       "GSM329409         0.655399  \n",
       "GSM329410         0.650308  \n",
       "GSM329411         0.637725  \n",
       "\n",
       "[5 rows x 54630 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a dataframe --> there is not the class\n",
    "df_x = pd.read_csv('https://drive.switch.ch/index.php/s/mBWgEscKK1wpHJJ/download?path=%2F&files=GSE13204-GPL570_series_matrix.txt.gz', sep='\\t', header=65)\n",
    "df_x = pd.DataFrame.transpose(df_x)\n",
    "new_header = df_x.iloc[0] \n",
    "df_x = df_x[1:] \n",
    "df_x.columns = new_header \n",
    "df_x = df_x.dropna(axis=1,how='all')\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Sample_characteristics_ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                !Sample_characteristics_ch1\n",
       "1  leukemia class: mature B-ALL with t(8;14)\n",
       "2  leukemia class: mature B-ALL with t(8;14)\n",
       "3  leukemia class: mature B-ALL with t(8;14)\n",
       "4  leukemia class: mature B-ALL with t(8;14)\n",
       "5  leukemia class: mature B-ALL with t(8;14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the classes of the samples\n",
    "df_y = pd.read_csv('https://drive.switch.ch/index.php/s/mBWgEscKK1wpHJJ/download?path=%2F&files=GSE13204-GPL570_series_matrix.txt.gz', sep='\\t', header=None, nrows=1, skiprows=np.arange(0, 40))\n",
    "df_y = pd.DataFrame.transpose(df_y)\n",
    "new_header = df_y.iloc[0] \n",
    "df_y = df_y[1:] \n",
    "df_y.columns = new_header \n",
    "df_y = df_y.dropna(axis=1,how='all')\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at', '1294_at',\n",
      "       '1316_at', '1320_at', '1405_i_at', '1431_at',\n",
      "       ...\n",
      "       'AFFX-HUMISGF3A/M97935_3_at', 'AFFX-HUMISGF3A/M97935_5_at',\n",
      "       'AFFX-HUMISGF3A/M97935_MA_at', 'AFFX-HUMISGF3A/M97935_MB_at',\n",
      "       'AFFX-HUMRGE/M10098_3_at', 'AFFX-HUMRGE/M10098_5_at',\n",
      "       'AFFX-HUMRGE/M10098_M_at', 'AFFX-M27830_3_at', 'AFFX-M27830_5_at',\n",
      "       'AFFX-M27830_M_at'],\n",
      "      dtype='object', name='ID_REF', length=54630)\n",
      "Index(['!Sample_characteristics_ch1'], dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "# define names\n",
    "x_labels = df_x.columns\n",
    "y_labels = df_y.columns\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb samples = 2096, nb features = 54630\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for features\n",
    "# check the shape\n",
    "print('Nb samples = '+str(df_x.shape[0]) + ', nb features = ' + str(df_x.shape[1]))\n",
    "# check if there are nan values\n",
    "count_nan = df_x.isna().sum().sum()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb samples = 2096, nb features = 1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for classes\n",
    "# check the shape\n",
    "print('Nb samples = '+str(df_y.shape[0]) + ', nb features = ' + str(df_y.shape[1]))\n",
    "# check if there are nan values\n",
    "count_nan = df_y.isna().sum().sum()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  18\n",
      "leukemia class: ALL with hyperdiploid karyotype: 40\n",
      "leukemia class: ALL with t(12;21): 58\n",
      "leukemia class: ALL with t(1;19): 36\n",
      "leukemia class: AML complex aberrant karyotype: 48\n",
      "leukemia class: AML with inv(16)/t(16;16): 28\n",
      "leukemia class: AML with normal karyotype + other abnormalities: 351\n",
      "leukemia class: AML with t(11q23)/MLL: 38\n",
      "leukemia class: AML with t(15;17): 37\n",
      "leukemia class: AML with t(8;21): 40\n",
      "leukemia class: CLL: 448\n",
      "leukemia class: CML: 76\n",
      "leukemia class: MDS: 206\n",
      "leukemia class: Non-leukemia and healthy bone marrow: 74\n",
      "leukemia class: Pro-B-ALL with t(11q23)/MLL: 70\n",
      "leukemia class: T-ALL: 174\n",
      "leukemia class: c-ALL/Pre-B-ALL with t(9;22): 122\n",
      "leukemia class: c-ALL/Pre-B-ALL without t(9;22): 237\n",
      "leukemia class: mature B-ALL with t(8;14): 13\n",
      "Total: 2096\n"
     ]
    }
   ],
   "source": [
    "# check number of samples per classes --> also get the number of classes\n",
    "def print_classes_occur(data):\n",
    "    classes, occurences = np.unique(data.values, return_counts=True)\n",
    "    print('Nb classes: ', len(classes))\n",
    "    for i in range(0, len(classes)):\n",
    "        print(classes[i] + ': ' + str(occurences[i]))\n",
    "    print('Total: '+ str(np.sum(occurences)))\n",
    "print_classes_occur(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation with different classes groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features dataset doesn't need manipulation. Only the classification is changing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  18\n",
      "leukemia class: ALL with hyperdiploid karyotype: 40\n",
      "leukemia class: ALL with t(12;21): 58\n",
      "leukemia class: ALL with t(1;19): 36\n",
      "leukemia class: AML complex aberrant karyotype: 48\n",
      "leukemia class: AML with inv(16)/t(16;16): 28\n",
      "leukemia class: AML with normal karyotype + other abnormalities: 351\n",
      "leukemia class: AML with t(11q23)/MLL: 38\n",
      "leukemia class: AML with t(15;17): 37\n",
      "leukemia class: AML with t(8;21): 40\n",
      "leukemia class: CLL: 448\n",
      "leukemia class: CML: 76\n",
      "leukemia class: MDS: 206\n",
      "leukemia class: Non-leukemia and healthy bone marrow: 74\n",
      "leukemia class: Pro-B-ALL with t(11q23)/MLL: 70\n",
      "leukemia class: T-ALL: 174\n",
      "leukemia class: c-ALL/Pre-B-ALL with t(9;22): 122\n",
      "leukemia class: c-ALL/Pre-B-ALL without t(9;22): 237\n",
      "leukemia class: mature B-ALL with t(8;14): 13\n",
      "Total: 2096\n"
     ]
    }
   ],
   "source": [
    "# dataset with all the classes\n",
    "df_y1 = df_y.copy()\n",
    "print_classes_occur(df_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  5\n",
      "ALL: 750\n",
      "AML: 542\n",
      "CLL: 448\n",
      "CML: 76\n",
      "OTHERS: 280\n",
      "Total: 2096\n"
     ]
    }
   ],
   "source": [
    "# dataset with 5 big classes --> ALL, AML, CLL, CML, and OTHERS\n",
    "df_y2 = df_y.copy()\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with hyperdiploid karyotype'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with t(12;21)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with t(1;19)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML complex aberrant karyotype'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with inv(16)/t(16;16)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with normal karyotype + other abnormalities'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(11q23)/MLL'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(15;17)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(8;21)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: CLL'] = 'CLL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: CML'] = 'CML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: MDS'] = 'OTHERS'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: Non-leukemia and healthy bone marrow'] = 'OTHERS'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: Pro-B-ALL with t(11q23)/MLL'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: T-ALL'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL with t(9;22)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL without t(9;22)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: mature B-ALL with t(8;14)'] = 'ALL'\n",
    "print_classes_occur(df_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  2\n",
      "NEGATIVE: 1648\n",
      "POSITIVE: 448\n",
      "Total: 2096\n"
     ]
    }
   ],
   "source": [
    "# dataset with positive and negative --> most frequent class is CLL\n",
    "df_y3 = df_y.copy()\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with hyperdiploid karyotype'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with t(12;21)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with t(1;19)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML complex aberrant karyotype'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with inv(16)/t(16;16)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with normal karyotype + other abnormalities'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(11q23)/MLL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(15;17)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(8;21)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: CLL'] = 'POSITIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: CML'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: MDS'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: Non-leukemia and healthy bone marrow'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: Pro-B-ALL with t(11q23)/MLL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: T-ALL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL with t(9;22)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL without t(9;22)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: mature B-ALL with t(8;14)'] = 'NEGATIVE'\n",
    "print_classes_occur(df_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all the dataset into training and testing \n",
    "all_X_train = []\n",
    "all_y_train = []\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df_x, df_y1, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train1)\n",
    "all_y_train.append(y_train1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_x, df_y2, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train2)\n",
    "all_y_train.append(y_train2)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(df_x, df_y3, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train3)\n",
    "all_y_train.append(y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection 1 : filter-based methods (5k to 10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the name of the N features with the best scores\n",
    "def anova_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stability(X_train, y_train, nb_features, nb_iter, func):\n",
    "    selected_features = func(X_train, y_train, nb_features)\n",
    "    selected_features_test = []\n",
    "    for i in range(0, nb_iter):\n",
    "        selected_features_test.append(func(X_train, y_train, nb_features))\n",
    "    nb_false = 0\n",
    "    result = selected_features_test == selected_features\n",
    "    for i in range(0, len(selected_features_test)):\n",
    "        if(False in result[i]):\n",
    "            nb_false += 1\n",
    "    print(\"pourcentage not same : \", str((nb_false/len(selected_features_test))*100)) # 0% is good (always same)\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "{'anova_df1_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '209604_s_at',\n",
      "       '209346_s_at', '203127_s_at'], dtype=object), 'chi2_df1_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '205456_at',\n",
      "       '225080_at', '239657_x_at'], dtype=object), 'anova_df2_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '235587_at',\n",
      "       '1556346_at', '244304_at'], dtype=object), 'chi2_df2_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '212741_at',\n",
      "       '228310_at', '1555120_at'], dtype=object), 'anova_df3_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '226838_at',\n",
      "       '209208_at', '204442_x_at'], dtype=object), 'chi2_df3_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '240279_at',\n",
      "       '214331_at', '209536_s_at'], dtype=object), 'anova_df1_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '206857_s_at',\n",
      "       '218646_at', '215034_s_at'], dtype=object), 'chi2_df1_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '225522_at',\n",
      "       '1570039_at', '1564632_at'], dtype=object), 'anova_df2_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '1554628_at',\n",
      "       '235775_at', '226229_s_at'], dtype=object), 'chi2_df2_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '205081_at',\n",
      "       '222799_at', '212312_at'], dtype=object), 'anova_df3_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '236595_at',\n",
      "       '200873_s_at', '213471_at'], dtype=object), 'chi2_df3_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '228607_at',\n",
      "       '217211_at', '238476_at'], dtype=object), 'anova_df1_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '223113_at',\n",
      "       '231924_at', '218267_at'], dtype=object), 'chi2_df1_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '209544_at',\n",
      "       '219661_at', '212419_at'], dtype=object), 'anova_df2_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '224954_at',\n",
      "       '211740_at', '206868_at'], dtype=object), 'chi2_df2_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '219172_at',\n",
      "       '1554340_a_at', '241993_x_at'], dtype=object), 'anova_df3_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '224565_at',\n",
      "       '209271_at', '201007_at'], dtype=object), 'chi2_df3_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '217823_s_at',\n",
      "       '222423_at', '207328_at'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# generate features\n",
    "nb_test = 1\n",
    "features_number = [5000, 7500, 10000]\n",
    "dict_filters = dict()\n",
    "filters_name = ['anova', 'chi2']\n",
    "\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        dict_filters['anova_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, anova_filter)\n",
    "        # TODO: taking really long (136min on my machine) for results not better --> Google Colab has the same problem\n",
    "        # dict_filters['mutual_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, mutual_info_filter) \n",
    "        dict_filters['chi2_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, chi_filter)\n",
    "\n",
    "print(dict_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check precentage of same features in the sets\n",
    "def percentage_same_features(ar_features_set, title):\n",
    "    all_sizes = []\n",
    "    for i in range(0, len(ar_features_set)):\n",
    "        all_sizes.append(len(ar_features_set[i]))\n",
    "    result = reduce(np.intersect1d,(ar_features_set))\n",
    "    result = (len(result)/np.max(all_sizes))*100\n",
    "    print(title+' - same features: '+str(result)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_nb5000 - same features: 56.74%\n",
      "df2_nb5000 - same features: 57.49999999999999%\n",
      "df3_nb5000 - same features: 60.519999999999996%\n",
      "df1_nb7500 - same features: 60.45333333333333%\n",
      "df2_nb7500 - same features: 60.440000000000005%\n",
      "df3_nb7500 - same features: 65.61333333333333%\n",
      "df1_nb10000 - same features: 62.57%\n",
      "df2_nb10000 - same features: 63.370000000000005%\n",
      "df3_nb10000 - same features: 69.97%\n",
      "--------------------------------------------------\n",
      "anova_nb5000 - same features: 55.16%\n",
      "anova_nb7500 - same features: 58.93333333333334%\n",
      "anova_nb10000 - same features: 62.260000000000005%\n",
      "chi2_nb5000 - same features: 63.28%\n",
      "chi2_nb7500 - same features: 65.82666666666667%\n",
      "chi2_nb10000 - same features: 67.03%\n",
      "--------------------------------------------------\n",
      "nb5000 - same features: 30.380000000000003%\n",
      "nb7500 - same features: 34.93333333333333%\n",
      "nb10000 - same features: 38.45%\n"
     ]
    }
   ],
   "source": [
    "# test different combination of features subset to see which one are similar or not\n",
    "\n",
    "# check same features for different filters but same data with same nb features\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        id = 'df'+str(i+1)+'_nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for same filters with same nb features\n",
    "for name in filters_name:\n",
    "    for nb in features_number:\n",
    "        id1 = name\n",
    "        id2 = 'nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if (id1 in k and id2 in k)]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id1+'_'+id2)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for different filters but different data\n",
    "for nb in features_number:\n",
    "    id = 'nb'+str(nb)\n",
    "    arrays = []\n",
    "    for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "        arrays.append(dict_filters.get(key))\n",
    "    percentage_same_features(arrays, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the 38% of the same features from anova_10000 and chi2_10000 ang that results us in ~3'800 features.\n",
    "Those features were present in anova and chi2 feature selection for all the different dataset. We can still test the \n",
    "different other subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb features all: 3845\n",
      "Nb features anova: 6226\n",
      "Nb features chi2: 6703\n",
      "Nb features df1: 6257\n",
      "Nb features df2: 6337\n",
      "Nb features df1: 6997\n",
      "3845\n"
     ]
    }
   ],
   "source": [
    "# create the 'final' features subset from phase 1 with features in all the filters and datasets\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_all = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features all: '+str(len(p1_subset_all)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter anova\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('anova' in k and 'nb10000' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_anova = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features anova: '+str(len(p1_subset_anova)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter chi2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('chi2' in k and 'nb10000' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_chi2 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features chi2: '+str(len(p1_subset_chi2)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset1\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df1_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df1 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p1_subset_df1)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df2_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df2 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df2: '+str(len(p1_subset_df2)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset3\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df3_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df3 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p1_subset_df3)))\n",
    "\n",
    "all_subset_p1 = [p1_subset_all, p1_subset_anova, p1_subset_chi2, p1_subset_df1, p1_subset_df2, p1_subset_df3]\n",
    "print(len(reduce(np.intersect1d,(all_subset_p1)))) # the features in subset p1_subset_all are all present in the other subsets --> should be the case and it is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection 2 : wrapper and/or embedded methods (500 to 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37176ba76f492b21b2fecf45ebc9cc529b25c201e6fbd5e4aedbf6386b9e0dcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
