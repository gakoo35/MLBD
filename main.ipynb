{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP3 - Leukemia Feature Selection \n",
    "# Corpataux Sam, Koch Gaël"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from functools import reduce\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_3_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_5_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_MA_at</th>\n",
       "      <th>AFFX-HUMISGF3A/M97935_MB_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_3_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_5_at</th>\n",
       "      <th>AFFX-HUMRGE/M10098_M_at</th>\n",
       "      <th>AFFX-M27830_3_at</th>\n",
       "      <th>AFFX-M27830_5_at</th>\n",
       "      <th>AFFX-M27830_M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.361346</td>\n",
       "      <td>0.450274</td>\n",
       "      <td>0.431178</td>\n",
       "      <td>0.405517</td>\n",
       "      <td>0.160812</td>\n",
       "      <td>0.568845</td>\n",
       "      <td>0.236371</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.793796</td>\n",
       "      <td>0.101112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718074</td>\n",
       "      <td>0.433772</td>\n",
       "      <td>0.516903</td>\n",
       "      <td>0.480186</td>\n",
       "      <td>0.416394</td>\n",
       "      <td>0.480112</td>\n",
       "      <td>0.474266</td>\n",
       "      <td>0.196546</td>\n",
       "      <td>0.455276</td>\n",
       "      <td>0.607962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.396426</td>\n",
       "      <td>0.559457</td>\n",
       "      <td>0.402577</td>\n",
       "      <td>0.437968</td>\n",
       "      <td>0.08913</td>\n",
       "      <td>0.526262</td>\n",
       "      <td>0.370959</td>\n",
       "      <td>0.118863</td>\n",
       "      <td>0.411771</td>\n",
       "      <td>0.231975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578789</td>\n",
       "      <td>0.305685</td>\n",
       "      <td>0.389508</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.567414</td>\n",
       "      <td>0.588449</td>\n",
       "      <td>0.575516</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.570179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.419317</td>\n",
       "      <td>0.436466</td>\n",
       "      <td>0.306609</td>\n",
       "      <td>0.479352</td>\n",
       "      <td>0.117863</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.348458</td>\n",
       "      <td>0.095052</td>\n",
       "      <td>0.621742</td>\n",
       "      <td>0.249171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47976</td>\n",
       "      <td>0.221501</td>\n",
       "      <td>0.248076</td>\n",
       "      <td>0.277969</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>0.498713</td>\n",
       "      <td>0.522232</td>\n",
       "      <td>0.157139</td>\n",
       "      <td>0.542367</td>\n",
       "      <td>0.655399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.424651</td>\n",
       "      <td>0.512677</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.484471</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>0.452757</td>\n",
       "      <td>0.393106</td>\n",
       "      <td>0.337601</td>\n",
       "      <td>0.481378</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534108</td>\n",
       "      <td>0.182823</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.196156</td>\n",
       "      <td>0.270626</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.414519</td>\n",
       "      <td>0.186461</td>\n",
       "      <td>0.468462</td>\n",
       "      <td>0.650308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.194097</td>\n",
       "      <td>0.355157</td>\n",
       "      <td>0.453368</td>\n",
       "      <td>0.180248</td>\n",
       "      <td>0.571522</td>\n",
       "      <td>0.188911</td>\n",
       "      <td>0.217023</td>\n",
       "      <td>0.772696</td>\n",
       "      <td>0.27619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65905</td>\n",
       "      <td>0.047018</td>\n",
       "      <td>0.224651</td>\n",
       "      <td>0.354375</td>\n",
       "      <td>0.32994</td>\n",
       "      <td>0.404139</td>\n",
       "      <td>0.184868</td>\n",
       "      <td>0.136972</td>\n",
       "      <td>0.24414</td>\n",
       "      <td>0.637725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF    1007_s_at   1053_at    117_at    121_at 1255_g_at   1294_at  \\\n",
       "GSM329407  0.361346  0.450274  0.431178  0.405517  0.160812  0.568845   \n",
       "GSM329408  0.396426  0.559457  0.402577  0.437968   0.08913  0.526262   \n",
       "GSM329409  0.419317  0.436466  0.306609  0.479352  0.117863  0.532214   \n",
       "GSM329410  0.424651  0.512677  0.217119  0.484471  0.222672  0.452757   \n",
       "GSM329411  0.287776  0.194097  0.355157  0.453368  0.180248  0.571522   \n",
       "\n",
       "ID_REF      1316_at   1320_at 1405_i_at   1431_at  ...  \\\n",
       "GSM329407  0.236371  0.020181  0.793796  0.101112  ...   \n",
       "GSM329408  0.370959  0.118863  0.411771  0.231975  ...   \n",
       "GSM329409  0.348458  0.095052  0.621742  0.249171  ...   \n",
       "GSM329410  0.393106  0.337601  0.481378  0.078431  ...   \n",
       "GSM329411  0.188911  0.217023  0.772696   0.27619  ...   \n",
       "\n",
       "ID_REF    AFFX-HUMISGF3A/M97935_3_at AFFX-HUMISGF3A/M97935_5_at  \\\n",
       "GSM329407                   0.718074                   0.433772   \n",
       "GSM329408                   0.578789                   0.305685   \n",
       "GSM329409                    0.47976                   0.221501   \n",
       "GSM329410                   0.534108                   0.182823   \n",
       "GSM329411                    0.65905                   0.047018   \n",
       "\n",
       "ID_REF    AFFX-HUMISGF3A/M97935_MA_at AFFX-HUMISGF3A/M97935_MB_at  \\\n",
       "GSM329407                    0.516903                    0.480186   \n",
       "GSM329408                    0.389508                    0.370612   \n",
       "GSM329409                    0.248076                    0.277969   \n",
       "GSM329410                    0.355785                    0.196156   \n",
       "GSM329411                    0.224651                    0.354375   \n",
       "\n",
       "ID_REF    AFFX-HUMRGE/M10098_3_at AFFX-HUMRGE/M10098_5_at  \\\n",
       "GSM329407                0.416394                0.480112   \n",
       "GSM329408                0.567414                0.588449   \n",
       "GSM329409                0.480558                0.498713   \n",
       "GSM329410                0.270626                0.520508   \n",
       "GSM329411                 0.32994                0.404139   \n",
       "\n",
       "ID_REF    AFFX-HUMRGE/M10098_M_at AFFX-M27830_3_at AFFX-M27830_5_at  \\\n",
       "GSM329407                0.474266         0.196546         0.455276   \n",
       "GSM329408                0.575516         0.296013         0.499546   \n",
       "GSM329409                0.522232         0.157139         0.542367   \n",
       "GSM329410                0.414519         0.186461         0.468462   \n",
       "GSM329411                0.184868         0.136972          0.24414   \n",
       "\n",
       "ID_REF    AFFX-M27830_M_at  \n",
       "GSM329407         0.607962  \n",
       "GSM329408         0.570179  \n",
       "GSM329409         0.655399  \n",
       "GSM329410         0.650308  \n",
       "GSM329411         0.637725  \n",
       "\n",
       "[5 rows x 54630 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a dataframe --> there is not the class\n",
    "df_x = pd.read_csv('https://drive.switch.ch/index.php/s/mBWgEscKK1wpHJJ/download?path=%2F&files=GSE13204-GPL570_series_matrix.txt.gz', sep='\\t', header=65)\n",
    "df_x = pd.DataFrame.transpose(df_x)\n",
    "new_header = df_x.iloc[0] \n",
    "df_x = df_x[1:] \n",
    "df_x.columns = new_header \n",
    "df_x = df_x.dropna(axis=1,how='all')\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Sample_characteristics_ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leukemia class: mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                !Sample_characteristics_ch1\n",
       "1  leukemia class: mature B-ALL with t(8;14)\n",
       "2  leukemia class: mature B-ALL with t(8;14)\n",
       "3  leukemia class: mature B-ALL with t(8;14)\n",
       "4  leukemia class: mature B-ALL with t(8;14)\n",
       "5  leukemia class: mature B-ALL with t(8;14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the classes of the samples\n",
    "df_y = pd.read_csv('https://drive.switch.ch/index.php/s/mBWgEscKK1wpHJJ/download?path=%2F&files=GSE13204-GPL570_series_matrix.txt.gz', sep='\\t', header=None, nrows=1, skiprows=np.arange(0, 40))\n",
    "df_y = pd.DataFrame.transpose(df_y)\n",
    "new_header = df_y.iloc[0] \n",
    "df_y = df_y[1:] \n",
    "df_y.columns = new_header \n",
    "df_y = df_y.dropna(axis=1,how='all')\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at', '1294_at',\n",
      "       '1316_at', '1320_at', '1405_i_at', '1431_at',\n",
      "       ...\n",
      "       'AFFX-HUMISGF3A/M97935_3_at', 'AFFX-HUMISGF3A/M97935_5_at',\n",
      "       'AFFX-HUMISGF3A/M97935_MA_at', 'AFFX-HUMISGF3A/M97935_MB_at',\n",
      "       'AFFX-HUMRGE/M10098_3_at', 'AFFX-HUMRGE/M10098_5_at',\n",
      "       'AFFX-HUMRGE/M10098_M_at', 'AFFX-M27830_3_at', 'AFFX-M27830_5_at',\n",
      "       'AFFX-M27830_M_at'],\n",
      "      dtype='object', name='ID_REF', length=54630)\n",
      "Index(['!Sample_characteristics_ch1'], dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "# define names\n",
    "x_labels = df_x.columns\n",
    "y_labels = df_y.columns\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb samples = 2096, nb features = 54630\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for features\n",
    "# check the shape\n",
    "print('Nb samples = '+str(df_x.shape[0]) + ', nb features = ' + str(df_x.shape[1]))\n",
    "# check if there are nan values\n",
    "count_nan = df_x.isna().sum().sum()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb samples = 2096, nb features = 1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for classes\n",
    "# check the shape\n",
    "print('Nb samples = '+str(df_y.shape[0]) + ', nb features = ' + str(df_y.shape[1]))\n",
    "# check if there are nan values\n",
    "count_nan = df_y.isna().sum().sum()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  18\n",
      "leukemia class: ALL with hyperdiploid karyotype: 40\n",
      "leukemia class: ALL with t(12;21): 58\n",
      "leukemia class: ALL with t(1;19): 36\n",
      "leukemia class: AML complex aberrant karyotype: 48\n",
      "leukemia class: AML with inv(16)/t(16;16): 28\n",
      "leukemia class: AML with normal karyotype + other abnormalities: 351\n",
      "leukemia class: AML with t(11q23)/MLL: 38\n",
      "leukemia class: AML with t(15;17): 37\n",
      "leukemia class: AML with t(8;21): 40\n",
      "leukemia class: CLL: 448\n",
      "leukemia class: CML: 76\n",
      "leukemia class: MDS: 206\n",
      "leukemia class: Non-leukemia and healthy bone marrow: 74\n",
      "leukemia class: Pro-B-ALL with t(11q23)/MLL: 70\n",
      "leukemia class: T-ALL: 174\n",
      "leukemia class: c-ALL/Pre-B-ALL with t(9;22): 122\n",
      "leukemia class: c-ALL/Pre-B-ALL without t(9;22): 237\n",
      "leukemia class: mature B-ALL with t(8;14): 13\n",
      "Total: 2096\n"
     ]
    }
   ],
   "source": [
    "# check number of samples per classes --> also get the number of classes\n",
    "def print_classes_occur(data):\n",
    "    classes, occurences = np.unique(data.values, return_counts=True)\n",
    "    print('Nb classes: ', len(classes))\n",
    "    for i in range(0, len(classes)):\n",
    "        print(classes[i] + ': ' + str(occurences[i]))\n",
    "    print('Total: '+ str(np.sum(occurences)))\n",
    "print_classes_occur(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation with different classes groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features dataset doesn't need manipulation. Only the classification is changing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  18\n",
      "leukemia class: ALL with hyperdiploid karyotype: 40\n",
      "leukemia class: ALL with t(12;21): 58\n",
      "leukemia class: ALL with t(1;19): 36\n",
      "leukemia class: AML complex aberrant karyotype: 48\n",
      "leukemia class: AML with inv(16)/t(16;16): 28\n",
      "leukemia class: AML with normal karyotype + other abnormalities: 351\n",
      "leukemia class: AML with t(11q23)/MLL: 38\n",
      "leukemia class: AML with t(15;17): 37\n",
      "leukemia class: AML with t(8;21): 40\n",
      "leukemia class: CLL: 448\n",
      "leukemia class: CML: 76\n",
      "leukemia class: MDS: 206\n",
      "leukemia class: Non-leukemia and healthy bone marrow: 74\n",
      "leukemia class: Pro-B-ALL with t(11q23)/MLL: 70\n",
      "leukemia class: T-ALL: 174\n",
      "leukemia class: c-ALL/Pre-B-ALL with t(9;22): 122\n",
      "leukemia class: c-ALL/Pre-B-ALL without t(9;22): 237\n",
      "leukemia class: mature B-ALL with t(8;14): 13\n",
      "Total: 2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gakoo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset with all the classes\n",
    "df_y1 = df_y.copy()\n",
    "print_classes_occur(df_y1)\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(df_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  5\n",
      "ALL: 750\n",
      "AML: 542\n",
      "CLL: 448\n",
      "CML: 76\n",
      "OTHERS: 280\n",
      "Total: 2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gakoo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset with 5 big classes --> ALL, AML, CLL, CML, and OTHERS\n",
    "df_y2 = df_y.copy()\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with hyperdiploid karyotype'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with t(12;21)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: ALL with t(1;19)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML complex aberrant karyotype'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with inv(16)/t(16;16)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with normal karyotype + other abnormalities'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(11q23)/MLL'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(15;17)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: AML with t(8;21)'] = 'AML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: CLL'] = 'CLL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: CML'] = 'CML'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: MDS'] = 'OTHERS'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: Non-leukemia and healthy bone marrow'] = 'OTHERS'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: Pro-B-ALL with t(11q23)/MLL'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: T-ALL'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL with t(9;22)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL without t(9;22)'] = 'ALL'\n",
    "df_y2.loc[df_y2[y_labels.values[0]] == 'leukemia class: mature B-ALL with t(8;14)'] = 'ALL'\n",
    "print_classes_occur(df_y2)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(df_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb classes:  2\n",
      "NEGATIVE: 1648\n",
      "POSITIVE: 448\n",
      "Total: 2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gakoo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset with positive and negative --> most frequent class is CLL\n",
    "df_y3 = df_y.copy()\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with hyperdiploid karyotype'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with t(12;21)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: ALL with t(1;19)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML complex aberrant karyotype'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with inv(16)/t(16;16)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with normal karyotype + other abnormalities'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(11q23)/MLL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(15;17)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: AML with t(8;21)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: CLL'] = 'POSITIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: CML'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: MDS'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: Non-leukemia and healthy bone marrow'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: Pro-B-ALL with t(11q23)/MLL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: T-ALL'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL with t(9;22)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: c-ALL/Pre-B-ALL without t(9;22)'] = 'NEGATIVE'\n",
    "df_y3.loc[df_y3[y_labels.values[0]] == 'leukemia class: mature B-ALL with t(8;14)'] = 'NEGATIVE'\n",
    "print_classes_occur(df_y3)\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(df_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all the dataset into training and testing \n",
    "all_X_train = []\n",
    "all_y_train = []\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df_x, df_y1, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train1)\n",
    "all_y_train.append(y_train1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_x, df_y2, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train2)\n",
    "all_y_train.append(y_train2)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(df_x, df_y3, test_size=0.3, random_state=42)\n",
    "all_X_train.append(X_train3)\n",
    "all_y_train.append(y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection 1 : filter-based methods (5k to 10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the name of the N features with the best scores\n",
    "def anova_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_filter(X_train, y_train, nb_features):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = fs.scores_.argsort()\n",
    "    sorted_features = np.array(x_labels.values)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stability(X_train, y_train, nb_features, nb_iter, func):\n",
    "    selected_features = func(X_train, y_train, nb_features)\n",
    "    selected_features_test = []\n",
    "    for i in range(0, nb_iter):\n",
    "        selected_features_test.append(func(X_train, y_train, nb_features))\n",
    "    nb_false = 0\n",
    "    result = selected_features_test == selected_features\n",
    "    for i in range(0, len(selected_features_test)):\n",
    "        if(False in result[i]):\n",
    "            nb_false += 1\n",
    "    print(\"pourcentage not same : \", str((nb_false/len(selected_features_test))*100)) # 0% is good (always same)\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "{'anova_df1_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '209604_s_at',\n",
      "       '209346_s_at', '203127_s_at'], dtype=object), 'chi2_df1_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '205456_at',\n",
      "       '225080_at', '239657_x_at'], dtype=object), 'anova_df2_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '235587_at',\n",
      "       '1556346_at', '244304_at'], dtype=object), 'chi2_df2_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '212741_at',\n",
      "       '228310_at', '1555120_at'], dtype=object), 'anova_df3_nb5000': array(['226147_s_at', '220118_at', '239287_at', ..., '226838_at',\n",
      "       '209208_at', '204442_x_at'], dtype=object), 'chi2_df3_nb5000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '240279_at',\n",
      "       '214331_at', '209536_s_at'], dtype=object), 'anova_df1_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '206857_s_at',\n",
      "       '218646_at', '215034_s_at'], dtype=object), 'chi2_df1_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '225522_at',\n",
      "       '1570039_at', '1564632_at'], dtype=object), 'anova_df2_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '1554628_at',\n",
      "       '235775_at', '226229_s_at'], dtype=object), 'chi2_df2_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '205081_at',\n",
      "       '222799_at', '212312_at'], dtype=object), 'anova_df3_nb7500': array(['226147_s_at', '220118_at', '239287_at', ..., '236595_at',\n",
      "       '200873_s_at', '213471_at'], dtype=object), 'chi2_df3_nb7500': array(['220118_at', '206760_s_at', '226147_s_at', ..., '228607_at',\n",
      "       '217211_at', '238476_at'], dtype=object), 'anova_df1_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '223113_at',\n",
      "       '231924_at', '218267_at'], dtype=object), 'chi2_df1_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '209544_at',\n",
      "       '219661_at', '212419_at'], dtype=object), 'anova_df2_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '224954_at',\n",
      "       '211740_at', '206868_at'], dtype=object), 'chi2_df2_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '219172_at',\n",
      "       '1554340_a_at', '241993_x_at'], dtype=object), 'anova_df3_nb10000': array(['226147_s_at', '220118_at', '239287_at', ..., '224565_at',\n",
      "       '209271_at', '201007_at'], dtype=object), 'chi2_df3_nb10000': array(['220118_at', '206760_s_at', '226147_s_at', ..., '217823_s_at',\n",
      "       '222423_at', '207328_at'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# generate features\n",
    "nb_test = 1\n",
    "features_number = [5000, 7500, 10000]\n",
    "dict_filters = dict()\n",
    "filters_name = ['anova', 'chi2']\n",
    "\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        dict_filters['anova_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, anova_filter)\n",
    "        # TODO: taking really long (136min on my machine) for results not better --> Google Colab has the same problem\n",
    "        # dict_filters['mutual_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, mutual_info_filter) \n",
    "        dict_filters['chi2_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, chi_filter)\n",
    "\n",
    "print(dict_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check precentage of same features in the sets\n",
    "def percentage_same_features(ar_features_set, title):\n",
    "    all_sizes = []\n",
    "    for i in range(0, len(ar_features_set)):\n",
    "        all_sizes.append(len(ar_features_set[i]))\n",
    "    result = reduce(np.intersect1d,(ar_features_set))\n",
    "    result = (len(result)/np.max(all_sizes))*100\n",
    "    print(title+' - same features: '+str(result)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_nb5000 - same features: 56.74%\n",
      "df2_nb5000 - same features: 57.49999999999999%\n",
      "df3_nb5000 - same features: 60.519999999999996%\n",
      "df1_nb7500 - same features: 60.45333333333333%\n",
      "df2_nb7500 - same features: 60.440000000000005%\n",
      "df3_nb7500 - same features: 65.61333333333333%\n",
      "df1_nb10000 - same features: 62.57%\n",
      "df2_nb10000 - same features: 63.370000000000005%\n",
      "df3_nb10000 - same features: 69.97%\n",
      "--------------------------------------------------\n",
      "anova_nb5000 - same features: 55.16%\n",
      "anova_nb7500 - same features: 58.93333333333334%\n",
      "anova_nb10000 - same features: 62.260000000000005%\n",
      "chi2_nb5000 - same features: 63.28%\n",
      "chi2_nb7500 - same features: 65.82666666666667%\n",
      "chi2_nb10000 - same features: 67.03%\n",
      "--------------------------------------------------\n",
      "nb5000 - same features: 30.380000000000003%\n",
      "nb7500 - same features: 34.93333333333333%\n",
      "nb10000 - same features: 38.45%\n"
     ]
    }
   ],
   "source": [
    "# test different combination of features subset to see which one are similar or not\n",
    "\n",
    "# check same features for different filters but same data with same nb features\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        id = 'df'+str(i+1)+'_nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for same filters with same nb features\n",
    "for name in filters_name:\n",
    "    for nb in features_number:\n",
    "        id1 = name\n",
    "        id2 = 'nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if (id1 in k and id2 in k)]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id1+'_'+id2)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for different filters but different data\n",
    "for nb in features_number:\n",
    "    id = 'nb'+str(nb)\n",
    "    arrays = []\n",
    "    for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "        arrays.append(dict_filters.get(key))\n",
    "    percentage_same_features(arrays, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the 38% of the same features from anova_10000 and chi2_10000 ang that results us in ~3'800 features.\n",
    "Those features were present in anova and chi2 feature selection for all the different dataset. We can still test the \n",
    "different other subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb features all: 3845\n",
      "Nb features anova: 6226\n",
      "Nb features chi2: 6703\n",
      "Nb features df1: 6257\n",
      "Nb features df2: 6337\n",
      "Nb features df1: 6997\n",
      "3845\n"
     ]
    }
   ],
   "source": [
    "# create the 'final' features subset from phase 1 with features in all the filters and datasets\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_all = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features all: '+str(len(p1_subset_all)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter anova\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('anova' in k and 'nb10000' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_anova = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features anova: '+str(len(p1_subset_anova)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter chi2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('chi2' in k and 'nb10000' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_chi2 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features chi2: '+str(len(p1_subset_chi2)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset1\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df1_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df1 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p1_subset_df1)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df2_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df2 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df2: '+str(len(p1_subset_df2)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset3\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df3_nb10000' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p1_subset_df3 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p1_subset_df3)))\n",
    "\n",
    "all_subset_p1 = [p1_subset_all, p1_subset_anova, p1_subset_chi2, p1_subset_df1, p1_subset_df2, p1_subset_df3]\n",
    "print(len(reduce(np.intersect1d,(all_subset_p1)))) # the features in subset p1_subset_all are all present in the other subsets --> should be the case and it is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be interesting to check where those 3845 features come from --> if a subset is more restrictive than the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection 2 : wrapper and/or embedded methods (500 to 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467, 3845)\n",
      "(1467, 3845)\n",
      "--------------------------------------------------\n",
      "(1467, 3845)\n",
      "(1467, 3845)\n",
      "--------------------------------------------------\n",
      "(1467, 3845)\n",
      "(1467, 3845)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# start by removing unused features\n",
    "for i in range(len(all_X_train)):\n",
    "    print(all_X_train[i].shape)\n",
    "    all_X_train[i] = all_X_train[i][p1_subset_all] # TODO: change p1_subset_all if you want to try different feature subset from phase 1\n",
    "    print(all_X_train[i].shape)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our functions for wrapper / embedded methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: wrapper methods takes too long --> not because of the algorithm used but because it is wrapped in RFE\n",
    "def decision_tree_wrapper(X_train, y_train, nb_features):\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=nb_features)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    return np.array(p1_subset_all)[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_embedded(X_train, y_train, nb_features):\n",
    "    dtc = DecisionTreeClassifier(random_state=42) \n",
    "    dtc.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = dtc.feature_importances_.argsort()\n",
    "    sorted_features = np.array(p1_subset_all)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_embedded(X_train, y_train, nb_features):\n",
    "    dtc = RandomForestClassifier(random_state=42) # TODO: had to put the random state to have the same features each time\n",
    "    dtc.fit(X_train, y_train.values.ravel())\n",
    "    # sort the best features\n",
    "    order = dtc.feature_importances_.argsort()\n",
    "    sorted_features = np.array(p1_subset_all)[order[::-1]]\n",
    "    return sorted_features[0:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n",
      "pourcentage not same :  0.0\n"
     ]
    }
   ],
   "source": [
    "# now we can generate all our features selection\n",
    "nb_test = 1\n",
    "features_number = [500, 1000, 1500]\n",
    "dict_filters = dict()\n",
    "filters_name = ['tree', 'forest']\n",
    "\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        dict_filters['tree_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, decision_tree_embedded) \n",
    "        dict_filters['forest_df'+str(i+1)+'_nb'+str(nb)] = test_stability(all_X_train[i], all_y_train[i], nb, nb_test, random_forest_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_nb500 - same features: 19.400000000000002%\n",
      "df2_nb500 - same features: 19.8%\n",
      "df3_nb500 - same features: 14.799999999999999%\n",
      "df1_nb1000 - same features: 29.099999999999998%\n",
      "df2_nb1000 - same features: 30.5%\n",
      "df3_nb1000 - same features: 63.6%\n",
      "df1_nb1500 - same features: 41.199999999999996%\n",
      "df2_nb1500 - same features: 40.0%\n",
      "df3_nb1500 - same features: 78.26666666666667%\n",
      "--------------------------------------------------\n",
      "tree_nb500 - same features: 75.2%\n",
      "tree_nb1000 - same features: 89.8%\n",
      "tree_nb1500 - same features: 93.4%\n",
      "forest_nb500 - same features: 16.0%\n",
      "forest_nb1000 - same features: 19.7%\n",
      "forest_nb1500 - same features: 26.466666666666665%\n",
      "--------------------------------------------------\n",
      "nb500 - same features: 2.1999999999999997%\n",
      "nb1000 - same features: 10.0%\n",
      "nb1500 - same features: 19.133333333333333%\n"
     ]
    }
   ],
   "source": [
    "# test different combination of features subset to see which one are similar or not\n",
    "\n",
    "# check same features for different filters but same data with same nb features\n",
    "for nb in features_number:\n",
    "    for i in range(0, len(all_X_train)):\n",
    "        id = 'df'+str(i+1)+'_nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for same filters with same nb features\n",
    "for name in filters_name:\n",
    "    for nb in features_number:\n",
    "        id1 = name\n",
    "        id2 = 'nb'+str(nb)\n",
    "        arrays = []\n",
    "        for key in [k for k, v in dict_filters.items() if (id1 in k and id2 in k)]:\n",
    "            arrays.append(dict_filters.get(key))\n",
    "        percentage_same_features(arrays, id1+'_'+id2)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# check same features for different filters but different data\n",
    "for nb in features_number:\n",
    "    id = 'nb'+str(nb)\n",
    "    arrays = []\n",
    "    for key in [k for k, v in dict_filters.items() if id in k]:\n",
    "        arrays.append(dict_filters.get(key))\n",
    "    percentage_same_features(arrays, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have 287 features with the comparison of all the subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb features all: 287\n",
      "Nb features tree: 1401\n",
      "Nb features forest: 397\n",
      "Nb features df1: 618\n",
      "Nb features df2: 600\n",
      "Nb features df1: 1174\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "# create the 'final' features subset from phase 1 with features in all the filters and datasets\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'nb1500' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_all = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features all: '+str(len(p2_subset_all)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter anova\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('tree' in k and 'nb1500' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_tree = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features tree: '+str(len(p2_subset_tree)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the datasets but filter chi2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if ('forest' in k and 'nb1500' in k)]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_forest = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features forest: '+str(len(p2_subset_forest)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset1\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df1_nb1500' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_df1 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p2_subset_df1)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset2\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df2_nb1500' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_df2 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df2: '+str(len(p2_subset_df2)))\n",
    "\n",
    "# create the 'final' features subset from phase 1 with features in all the filters but in dataset3\n",
    "arrays = []\n",
    "for key in [k for k, v in dict_filters.items() if 'df3_nb1500' in k]:\n",
    "    arrays.append(dict_filters.get(key))\n",
    "p2_subset_df3 = reduce(np.intersect1d,(arrays))\n",
    "print('Nb features df1: '+str(len(p2_subset_df3)))\n",
    "\n",
    "all_subset_p2 = [p2_subset_all, p2_subset_tree, p2_subset_forest, p2_subset_df1, p2_subset_df2, p2_subset_df3]\n",
    "print(len(reduce(np.intersect1d,(all_subset_p2)))) # the features in subset p1_subset_all are all present in the other subsets --> should be the case and it is here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of ML methods with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7933227344992051\n",
      "f1 : 0.7841534176402326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gakoo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_train = le1.transform(y_train1)\n",
    "y_test = le1.transform(y_test1)\n",
    "model = GaussianNB()\n",
    "y_hat = model.fit(X_train1[p2_subset_all], y_train).predict(X_test1[p2_subset_all])\n",
    "acc = accuracy_score(y_hat, y_test)\n",
    "f1 = f1_score(y_hat, y_test, average='weighted')\n",
    "print('accuracy :', acc)\n",
    "print('f1 :', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37176ba76f492b21b2fecf45ebc9cc529b25c201e6fbd5e4aedbf6386b9e0dcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
